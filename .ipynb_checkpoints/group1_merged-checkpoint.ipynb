{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capstone\n",
    "#Group 1\n",
    "import webbrowser\n",
    "import requests\n",
    "import flask\n",
    "import sqlite3\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "class data:\n",
    "    def __init__(self):\n",
    "        #create table if not exists Jobs (jobTitle text, passWord text, userType text)\n",
    "        #info given by user\n",
    "        self.location=\"none\"\n",
    "        self.jobType=\"no type\"\n",
    "        self.skills=[]\n",
    "        self.exp=\"none\"\n",
    "        self.edu=\"none\"\n",
    "\n",
    "        #info given by api\n",
    "        self.age=[]#how old is the job listing\n",
    "        self.jobLst=[]\n",
    "        self.jobDist=[]\n",
    "        self.jobLocation=\"none\"\n",
    "        self.company=\"none\"\n",
    "        self.listing=[]\n",
    "        \n",
    "        # keywords used in skill identification\n",
    "        self.keyWordSkills = ['python', 'java', 'c++', 'sql', 'manage', 'javascript', 'linux', 'team', 'problem solving', 'front end', 'back end', 'html', 'css','json', 'xml','api', 'linux', 'nodejs', 'c#', 'spark', 'sas', 'matlab', 'excel', 'spark', 'hadoop', 'azure', 'spss', 'git', 'aws']\n",
    "        self.keyWordEdu = ['masters', 'bachelors', \"master's\", \"bachelor's\", 'phd', 'undergrad', 'graduate', 'undergraduate', 'ged', \"graduate's\", \"undergraduate's\", \"associate's\", 'doctoral']\n",
    "        self.aiKeys = ['ai', 'a.i.', 'artificial intelligence', 'artificial']\n",
    "        self.dlKeys= ['deep learning', 'neural networks', 'big data', 'deep', 'statistics']\n",
    "        self.mlKeys = ['data mining', 'machine learning', 'cnn', 'rbm', \n",
    "          'machine', 'natural language', 'regression', 'fault diagnosis', 'intrusion detection']\n",
    "        self.seKeys = ['software engineer', 'software development','code']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.exp\n",
    "    \n",
    "    def port_to_csv(self):\n",
    "        inpsql3 = sqlite3.connect('Flask_Jade_Sample/TestFlaskJadeWeb/Users.db')\n",
    "        sql3_cursor = inpsql3.cursor()\n",
    "        sql3_cursor.execute('SELECT * FROM JOBS')\n",
    "        with open('output.csv','w') as out_csv_file:\n",
    "            csv_out = csv.writer(out_csv_file)\n",
    "            # write header                        \n",
    "            csv_out.writerow([d[0] for d in sql3_cursor.description])\n",
    "            # write data                          \n",
    "            for result in sql3_cursor:\n",
    "                csv_out.writerow(result)\n",
    "        inpsql3.close()\n",
    "    \n",
    "    # TODO: remove function?\n",
    "    # sends the data allocated to the database\n",
    "    def testing(self):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # create table if not exists\n",
    "        # columns used for the primary key implicitly cannot be null\n",
    "        # columns skills and education are comma separated string representations of lists\n",
    "        table_query = \"\"\"create table if not exists JOBS\n",
    "                            (location text, company text, datePosted text, postUrl text, \n",
    "                            jobType text, jobTitle text, jobDes text, jobApp text, salary text,\n",
    "                            skills text, category text, education text,\n",
    "                            PRIMARY KEY (company, jobTitle, location))\"\"\"\n",
    "        cursor.execute(table_query)\n",
    "        conn.commit()\n",
    "        \n",
    "        for i in range(len(self.jobLst)):\n",
    "            insert_query = \"\"\"insert or ignore into JOBS (location, company, datePosted, postUrl, \n",
    "                                                jobType, jobTitle, jobDes, jobApp, salary, skills,\n",
    "                                                category, education) \n",
    "                                    VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\"\"\"\n",
    "            \n",
    "            #print(self.jobLst[i]['Skills'])\n",
    "            data_tuples = (self.jobLst[i]['Location'], self.jobLst[i]['Company'], \n",
    "                           self.jobLst[i]['Time-Posted'], self.jobLst[i]['Page-Addr'], \n",
    "                           self.jobLst[i]['Contract-Type'], self.jobLst[i]['Title'], \n",
    "                           self.jobLst[i]['Desc'], self.jobLst[i]['Apply-To'], self.jobLst[i]['Salary'],\n",
    "                           lst_to_str(self.jobLst[i]['Skills']), self.jobLst[i]['Category'], lst_to_str(self.jobLst[i]['Education']))\n",
    "\n",
    "            cursor.execute(insert_query, data_tuples)\n",
    "\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    # searches backend for whatever search term\n",
    "    def searchJobs(self, term):\n",
    "        results = []\n",
    "        \n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        cursor = conn.cursor()\n",
    "        select_query = \"\"\"select * from JOBS \"\"\" # change JOBS to whatever table you want to see\n",
    "        \n",
    "        cursor.execute(select_query)\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        for i in range(len(records)):\n",
    "            if term in records[i]:\n",
    "                results.append(records[i])\n",
    "                #return records[i] # TODO: remove to return multiple results\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    # returns tuple list of all records in jobs table sorted by the job title in ascending order\n",
    "    def getAllJobs(self):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        select_query = \"\"\"select * from Jobs order by jobTitle ASC\"\"\"\n",
    "        cursor.execute(select_query)\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return [dict(row) for row in records]\n",
    "    \n",
    "    def getAllUsers(self):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        select_query = \"\"\"select * from Useres\"\"\"\n",
    "        cursor.execute(select_query)\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return [dict(row) for row in records]\n",
    "\n",
    "    # returns tuple list of jobs starting from the offset and getting as many as amount\n",
    "    # 0 based indexing means offset at 1 will start at second index\n",
    "    def getNJobs(self, offset, amt):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        select_query = \"\"\"select * from Jobs order by jobTitle ASC\"\"\"\n",
    "        cursor.execute(select_query)\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return [[records.index(row), dict(row)] for row in records[offset:offset+amt]]\n",
    "    \n",
    "    # modification of getNJobs\n",
    "    # similar design but will search the specified column (col) for the search term (term)\n",
    "    # return is the same\n",
    "    # col MUST BE a column header\n",
    "    def getNJobsByQuery (self, term, col, offset, amt):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        select_query = 'select * from Jobs where '+ col+ ' like ? order by jobTitle ASC'\n",
    "        cursor.execute(select_query, ('%'+term+'%',)) # pattern matching\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return [[records.index(row), dict(row)] for row in records[offset:offset+amt]]\n",
    "    \n",
    "    # returns a single job as a dictionary based on its index when sorting by title\n",
    "    def getNthJob(self, n):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        select_query = \"\"\"select * from Jobs order by jobTitle ASC\"\"\"\n",
    "        cursor.execute(select_query)\n",
    "        records = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        return [dict(row) for row in records][n]\n",
    "    \n",
    "    # deletes the jobs table entirely\n",
    "    def destroyJobs(self):\n",
    "        conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "        cursor = conn.cursor()\n",
    "        table_query = 'DROP TABLE JOBS'\n",
    "        cursor.execute(table_query)\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    \n",
    "###CAN CHANGE TO RUN LINKS THROUGH METHODS (have links as method parameters)\n",
    "\n",
    "    #returns list of links of positions without location specification \n",
    "    def onlylinks(self):\n",
    "        linklist = []\n",
    "        url = 'https://jobs.github.com/positions'\n",
    "        source = requests.get(url).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        for link in soup.find_all('a'):\n",
    "            links = link.get('href')\n",
    "            if \"http\" in links and '/positions/' in links:\n",
    "               #print (links)\n",
    "                linklist.append(link['href'])\n",
    "        return linklist\n",
    "            \n",
    "    # searches multiple pages and the given location\n",
    "    # returns list of all jobs found\n",
    "    # also returns links and other info\n",
    "    def hubJobs(self, jobX, loc, numPages):\n",
    "        print('entering github jobs')\n",
    "        multPageLocJobsWL = [] # will be populated with job dictionaries\n",
    "        for i in range (0, numPages): # iterating over pages until numPages\n",
    "            loc = '' if loc == '' else ('&location=' + loc.replace(' ', '+'))\n",
    "            jobX = '' if jobX == '' else ('&description=' + jobX.replace(' ', '+'))\n",
    "            finalURL = 'https://jobs.github.com/positions?utf8=✓' + loc + '&page=' + str(i) + jobX\n",
    "            #finalURL = url + loc # including location in filters\n",
    "            \n",
    "            source = requests.get(finalURL).text\n",
    "            soup = BeautifulSoup(source, 'lxml')\n",
    "            \n",
    "            for job in soup.find_all('tr', {'class':'job'} ): # iterating over individual job data\n",
    "                tmp = job.text.strip().split('\\n')\n",
    "                jb = {}\n",
    "                for x in range (0, len(tmp)):\n",
    "                    y = tmp[x].strip()\n",
    "                    if len(y) > 1 and not \"\\t\" in y:\n",
    "                        if x == 0:\n",
    "                            jb['Title'] = y\n",
    "                        \n",
    "                        elif x == 2:\n",
    "                            jb['Company'] = y\n",
    "                        \n",
    "                        elif x == 4:\n",
    "                            jb['Contract-Type'] = y\n",
    "                        \n",
    "                        elif x == 7:\n",
    "                            jb['Location'] = y\n",
    "                        \n",
    "                        elif x == 8:\n",
    "                            jb['Time-Posted'] = y\n",
    "                        \n",
    "                jb['Salary'] = 'N/A' # salary not listed on github\n",
    "                jobMeta = self.getPageMeta (job.find('td', {'class':'title'}).find('h4').find('a')['href']) # gets job info (applyto link and skills)\n",
    "                jb['Apply-To'] = jobMeta[0]\n",
    "                jb['Skills'] = jobMeta[1]\n",
    "                jb['Desc'] = jobMeta[2]\n",
    "                jb['Page-Addr'] = jobMeta[3]\n",
    "                jb['Education'] = jobMeta[4]\n",
    "                jb['Category'] = jobMeta[5]\n",
    "                \n",
    "                multPageLocJobsWL.append(jb)\n",
    "                \n",
    "        print('github jobs length ', len(multPageLocJobsWL))\n",
    "        return multPageLocJobsWL\n",
    "            \n",
    "    # TODO\n",
    "    #going to be a list of dictionaries ***TBA\n",
    "    #for now prints out several dictionaries for each job post on the page (50)\n",
    "    def create(self, job = '', loc = '', numPages = 1):\n",
    "        self.jobLst = self.hubJobs (job, loc, numPages) + self.indeedJobs(job, loc, numPages)\n",
    "        #self.jobLst += self.indeedJobs(job, loc, numPages)\n",
    "        self.testing()\n",
    "        print(\"create done\")\n",
    "\n",
    "    # returns 4 pieces of the specified page\n",
    "    #   [string:applyTo_link, list:skills, string:description, string:page_url, list:education]\n",
    "    def getPageMeta(self, url):\n",
    "        newSrc = requests.get(url).text\n",
    "        newSoup = BeautifulSoup(newSrc, 'lxml')\n",
    "        \n",
    "        # apply-to link\n",
    "        jobLink = ''\n",
    "        try:\n",
    "            jobLink = newSoup.find('div', {'class':'highlighted'}).find('a')['href']\n",
    "        except:\n",
    "            jobLink = url\n",
    "        \n",
    "        foundSkillsList = []\n",
    "        foundEduList = []\n",
    "\n",
    "        # parsing summary\n",
    "        summary = newSoup.find('div', class_=['column main', 'jobsearch-jobDescriptionText'])\n",
    "        sumtext = summary.text if not summary == None else 'N/A'\n",
    "        sumtext1 = sumtext.lower()\n",
    "        sumList = sumtext1.split()\n",
    "        \n",
    "        # education\n",
    "        for i in self.keyWordEdu:\n",
    "            if i in sumList and not i in foundEduList:\n",
    "                foundEduList.append(i)\n",
    "                \n",
    "        # skills\n",
    "        for i in self.keyWordSkills:\n",
    "            if i in sumList and not i in foundSkillsList:\n",
    "                foundSkillsList.append(i)\n",
    "        \n",
    "        # primitive text classification\n",
    "        # sums up occurunces of keywords and then appends the category tag associated with the highest count\n",
    "        cat = ''\n",
    "        aiCNT = 0\n",
    "        dlCNT = 0\n",
    "        mlCNT = 0\n",
    "        seCNT = 0\n",
    "        otherCNT = 0\n",
    "        for x in sumList:\n",
    "            if x in self.aiKeys:\n",
    "                aiCNT += 1\n",
    "                continue\n",
    "            elif x in self.dlKeys:\n",
    "                dlCNT += 1\n",
    "                continue\n",
    "            elif x in self.mlKeys:\n",
    "                mlCNT += 1\n",
    "                continue\n",
    "            elif x in self.seKeys:\n",
    "                seCNT += 1\n",
    "                continue\n",
    "                \n",
    "        mx = max(aiCNT, dlCNT, mlCNT, seCNT, otherCNT)\n",
    "        if aiCNT == mx:\n",
    "            cat = 'Artificial Intelligence'\n",
    "        elif dlCNT == mx:\n",
    "            cat = 'Deep Learning'\n",
    "        elif mlCNT == mx:\n",
    "            cat = 'Machine Learning'\n",
    "        elif seCNT == mx:\n",
    "            cat = 'Software Engineer'\n",
    "        elif otherCNT == mx: # consider difference of counts?\n",
    "            cat = 'Other'\n",
    "        \n",
    "        return [jobLink, foundSkillsList, sumtext, url, foundEduList, cat]\n",
    "    \n",
    "    ### Indeed ###\n",
    "    \n",
    "    # gets a list of dictionaries limited by the input parameters through indeed\n",
    "    def indeedJobs(self, job, location, maxPages):\n",
    "        print('entering indeed jobs')\n",
    "        baseLink = 'https://www.indeed.com/'\n",
    "        webAddr = baseLink + ('' if job == '' else 'jobs?q=' + job.replace (' ', '+'))\n",
    "        webAddr = webAddr + ('' if location == '' else '&l=' + location) + '&start=0'\n",
    "\n",
    "        jbPages = []\n",
    "        for x in range(0, maxPages):\n",
    "            link=webAddr.replace(webAddr[-1], str(x))\n",
    "            #jbPages.append(self.getDictNew(link))\n",
    "            source = requests.get(link).text\n",
    "            soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "            for div in soup.find_all ('div', class_='row', attrs={'class':'row'}):\n",
    "                linkElem = div.find('div', class_='title').a\n",
    "                title = linkElem.get('title') # TITLE\n",
    "                link = \"https://www.indeed.com\" + linkElem.get('href')   # LINK\n",
    "\n",
    "                payRAW = div.find(name='span', class_=['salaryText', 'sjcl', 'salary'])\n",
    "                pay = payRAW.text.replace('\\n', '') if not payRAW == None else 'N/A' # salary\n",
    "\n",
    "                co = div.find(name='span', class_=['company', 'result-link-source']).text.strip() # company\n",
    "                loc = div.find(['div', 'span'], attrs={'class': 'location'}).text # location\n",
    "                date = div.find('span', attrs={'class': 'date'}).text # date\n",
    "\n",
    "                jobMeta = self.getPageMeta(link)\n",
    "                newDict = {\n",
    "                    'Company':co, 'Location':loc, 'Title':title, \n",
    "                    'Time-Posted':date, 'Salary':pay, 'Link':link,\n",
    "                    'Contract-Type':'N/A'\n",
    "                }\n",
    "                newDict['Apply-To'] = jobMeta[0]\n",
    "                newDict['Skills'] = jobMeta[1]\n",
    "                newDict['Desc'] = jobMeta[2]\n",
    "                newDict['Page-Addr'] = jobMeta[3]\n",
    "                newDict['Education'] = jobMeta[4]\n",
    "                newDict['Category'] = jobMeta[5]\n",
    "\n",
    "                jbPages.append(newDict)\n",
    "        \n",
    "        print('indeed jobs length ', len(jbPages))\n",
    "        return jbPages\n",
    "    \n",
    "    # TODO: delete this\n",
    "    def getDictNew(self, url):\n",
    "        source = requests.get(url).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        tmpLst = []\n",
    "        for div in soup.find_all ('div', class_='row', attrs={'class':'row'}):\n",
    "            linkElem = div.find('div', class_='title').a\n",
    "            title = linkElem.get('title') # TITLE\n",
    "            link = \"https://www.indeed.com\" + linkElem.get('href')   # LINK\n",
    "\n",
    "            payRAW = div.find(name='span', class_=['salaryText', 'sjcl', 'salary'])\n",
    "            pay = payRAW.text.replace('\\n', '') if not payRAW == None else 'N/A' # salary\n",
    "\n",
    "            co = div.find(name='span', class_=['company', 'result-link-source']).text.strip() # company\n",
    "            loc = div.find(['div', 'span'], attrs={'class': 'location'}).text # location\n",
    "            date = div.find('span', attrs={'class': 'date'}).text # date\n",
    "            \n",
    "            jobMeta = self.getPageMeta(link)\n",
    "            newDict = {\n",
    "                'Company':co, 'Location':loc, 'Title':title, 'Time-Posted':date, 'Salary':pay, 'Link':link\n",
    "            }\n",
    "            newDict['Apply-To'] = jobMeta[0]\n",
    "            newDict['Skills'] = jobMeta[1]\n",
    "            newDict['Desc'] = jobMeta[2]\n",
    "            newDict['Page-Addr'] = jobMeta[3]\n",
    "            newDict['Education'] = jobMeta[4]\n",
    "            \n",
    "            tmpLst.append(newDict)\n",
    "        return tmpLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=data()\n",
    "#d.create('science', '', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  {'location': 'Corvallis, OR',\n",
       "   'company': 'Oregon State University Ecampus',\n",
       "   'datePosted': '12 days ago',\n",
       "   'postUrl': 'https://jobs.github.com/positions/3ac7ce46-18df-4b01-9d82-e7c896dd3fe2',\n",
       "   'jobType': 'Full Time',\n",
       "   'jobTitle': 'Analyst Programmer (Front-End Web Developer)',\n",
       "   'jobDes': '\\nThis recruitment will be used to fill two full-time Analyst Programmer, competency level 2, position for Ecampus at Oregon State University (OSU). These are limited duration classified positions anticipated to last 18 months.\\nOregon State University Ecampus is a growing, innovative and collaborative organization with a commitment to providing high-quality online degrees and programs.\\xa0OSU\\xa0Ecampus makes OSU’s exceptional learning experiences available to students throughout Oregon and around the world.\\nThe front-end web developer (analyst programmer, competency level 2) is a classified position within\\xa0OSU\\xa0Ecampus. The front-end web developer provides programming and multimedia support for\\xa0OSU\\xa0Ecampus programmatic and course needs. The multimedia team is part of the Course Development and Training (CDT) unit within the division of Ecampus. The\\xa0CDT\\xa0unit provides expertise and support for the development of online and hybrid courses, including instructional design services, innovative multimedia development, and faculty development programming and support. This position reports directly to the assistant director of\\xa0CDT.\\nWithin the\\xa0CDT\\xa0team, the front-end web developer will collaborate closely with other programmers on the multimedia web development team, instructional designers and faculty course developers to ensure high quality projects are produced. This position works closely and collaborates with faculty and administrators to assess how multimedia technologies can augment students’ abilities to meet course learning outcomes.\\nOregon State University and the division of Ecampus maintain and enhance a collaborative and inclusive community that is dedicated to equity and equal opportunity. All employees of the division are responsible for ensuring that these commitments are achieved. This position directly contributes to those goals by designing learning environments that are inclusive, accessible, and follow the best practices of Universal Design for Learning.\\nMinimum qualifications\\n\\nThis classification requires a basic foundation of knowledge and skills in systems analysis and related programming support functions generally obtained by a bachelor’s degree in computer science, or an equivalent amount of training and applied experience.\\nDemonstrated skill in front-end web development (Javascript, CSS3, HTML5)\\nDemonstrated skill in React and Redux.\\nExperience with source control / version control systems (such as Git)\\nExcellent written and oral communication skills\\nExperience developing in a collaborative team environment\\nA demonstrable commitment to promoting and enhancing diversity\\nThis position is designated as a critical or security-sensitive position; therefore, the incumbent must successfully complete a criminal history check and be determined to be position qualified as per\\xa0OSU\\xa0Standard 576-055-0000 et seq. Incumbents are required to self-report convictions and those in youth programs may have additional criminal history checks every 24 months.\\n\\nPreferred qualifications\\n\\nExperience with Serverless/AWS\\xa0(Amazon Web Services)\\nExperience with dependency and task management (npm, yarn)\\nExperience with mobile accessibility and responsive design\\nExperience integrating with APIs (REST)\\nExperience with universal design for learning.\\nExperience with Agile (scrum, kanban)\\nExperience working with a diverse group of people/teams.\\n\\nOSU seeks diversity as a source of enrichment for our university community. We are an Affirmative Action/Equal Opportunity employer, and particularly encourage applications from members of historically underrepresented racial/ethnic groups, women, individuals with disabilities, veterans, LGBTQ community members, and others who demonstrate the ability to help us achieve our vision of a diverse and inclusive community.\\nFor more information and to apply go to http://jobs.oregonstate.edu/postings/88459\\nFull consideration deadline: 3/1/2020\\nExtended deadline: 3/15/2020\\n',\n",
       "   'jobApp': 'http://jobs.oregonstate.edu/postings/88459',\n",
       "   'salary': 'N/A',\n",
       "   'skills': 'team',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [1,\n",
       "  {'location': 'Amsterdam',\n",
       "   'company': 'Shell',\n",
       "   'datePosted': 'over 1 year ago',\n",
       "   'postUrl': 'https://jobs.github.com/positions/f8c3413e-e99f-11e8-85e7-1cb84dad80e6',\n",
       "   'jobType': 'Full Time',\n",
       "   'jobTitle': 'Blockchain Analyst | Part of the Shell Graduate Programme',\n",
       "   'jobDes': '\\nBlockchain Analyst | Part of Shell Graduate Programme\\nLocation: Amsterdam\\nSummary\\nPart of our highly-reputed Graduate Programme, this placement in our Blockchain Centre of Excellence (CoE) is a chance to learn alongside some of the best minds and developers in the blockchain space and build your blockchain knowledge. You’ll be exploring potential applications across Shell – from supply chain and certification to mobility and energy.\\nThe placement\\nIn this placement, you’ll gain the skills to be a successful Blockchain Analyst with us. It’s a great time to join this new team – we’re still at the stage where we can educate colleagues and refine our strategy. Highlights include:\\n\\nExploring potential applications – whether that’s in our core gas and oil business or new areas such as new energies or electric vehicles.\\nAssisting on projects from ideation to deployment, working with bright, experienced analysts.\\nCarrying out market scans on new decentralised technology primitives.\\nCreating value cases for opportunities for blockchain in different business areas.\\nHelping shape the team’s approach and way of working.\\n\\nThis is the first of two Graduate Programme placements; your second could be in data engineering, data analytics, IT Architecture or a similar part of our business.\\nWho are you?\\nObviously, some insight into blockchain would be useful, but it’s not essential: we can bring you up to speed. You probably you have a background in Computer Science or Information Management but we’re also open to hearing from cryptographers, mathematicians or game theorists.\\nYou’ll be part of a start-up culture where we sometimes ‘colour outside the lines’ – that’s something you’ll need to embrace. To thrive here, you’ll definitely need to be able to think on your feet – you’re someone who loves coming up with original ideas and exploring different angles to solve a problem.\\nThe Shell Graduate Programme: a world of opportunities\\nJoin the IT Shell Graduate Programme and you can look forward to an industry-leading two- or three-year learning programme, offering real responsibility, engaging challenges and continued professional development.\\nThere’s never been a more exciting time to be part of the energy industry. Start your career at Shell and immerse yourself in innovative projects to find economically, socially and environmentally responsible solutions to the world’s energy needs. You’ll be learning alongside brilliant people from all over the world, with the resources and support to explore new ways of thinking and working – all in all, an unbeatable experience.\\nHelping you prepare\\nWe want you to be at your best when completing the assessments, so here are some top tips and some additional background information that may help you. Ace your application prep by reviewing our application tips.\\nReady to apply?\\nIf you’re excited by the chance to push boundaries and explore frontiers, click on this link:Click here to apply! to start you application. In the online application form, select “IT” as your preferred area of interest.\\n',\n",
       "   'jobApp': 'https://shellinternational.redirect.your-jobresponse.com/blockchain_analyst_part_of_the_shell_graduate_programme_amsterdam/236647/V819/apply',\n",
       "   'salary': 'N/A',\n",
       "   'skills': 'team',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': 'graduate'}],\n",
       " [2,\n",
       "  {'location': 'Chicago, IL 60654 (River North area)',\n",
       "   'company': 'Hulu',\n",
       "   'datePosted': '5 days ago',\n",
       "   'postUrl': 'https://www.indeed.com/rc/clk?jk=dfe62bb2c9818a96&fccid=6824fc1f087bd63e&vjs=3',\n",
       "   'jobType': 'N/A',\n",
       "   'jobTitle': 'Brand & Ad Effectiveness Analyst',\n",
       "   'jobDes': \"Hulu is the leading premium streaming service offering live and on-demand TV and movies, with and without commercials, both in and outside the home. Operating at the intersection of entertainment and technology, Hulu has a unique opportunity to be the number one choice for TV. We captivate and connect viewers with the stories they love, and we’re looking for people who are passionate about redefining TV through innovation, unconventional thinking, and embracing fun. Join us and see what Hulugan life is all about.\\nSUMMARY\\nHulu’s Advertising Sales Research Team is seeking a hardworking person to help build the future of television and innovate in the advertising and measurement space. The Ad Sales Research Analyst will lead projects and analyses to demonstrate the effectiveness of Hulu as an advertising platform that drives measurable results for our clients. The successful candidate will work directly with the sales team and research vendors to find and build solutions to measure the effectiveness of advertiser campaigns, ad products, and integrated solutions. If you’re the kind of person who obsesses over details, thrives in a collaborative environment and jumps at the opportunity to tackle new challenges, Hulu may be the place for you.\\nWHAT YOU'LL DO\\nMeasure advertiser campaign performance, positioning data into insights and actionable recommendations\\nTrack and monitor ad effectiveness projects across study life stage – from survey to recruitment, and analysis and creation of post-campaign deliverables\\nAssist in managing of custom primary research studies including advertising research and consumer insights\\nBuild topical research decks and monitor syndicated research sources to continuously incorporate updated information\\nAssess Hulu relative to other media properties and develop actionable insights to help improve Hulu’s positioning in the marketplace\\nWork collaboratively with the integrated marketing team to create sales materials, providing the necessary research to support and sell through marketing executions\\nConsult with sales and advertiser clients to provide them the context to help optimize Hulu media plans and buys, and making appropriate recommendations for research and measurement based on client KPIs\\nPosition Hulu as a leader with vision in innovative research by assisting in mining all sources and crafting Hulu Insights to be shared in the press and the marketplace\\nWHAT TO BRING\\n2+ years of media experience at a fast-paced web publisher, media agency or TV Network\\nStrong experience with quantitative research methodologies, survey design and analysis\\nKnowledge of the media landscape and preferably the digital media landscape\\nProven ability to analyze and interpret qualitative and quantitative research with client needs in mind, write clearly, and translate data into clear insights\\nExperience successfully communicating at all levels both verbally and in writing\\nProven team player with the ability to tackle and manage various projects in a timely manner\\nStrong mathematical skills and an interest in finding compelling stories in the data through in-depth analyses\\nAbility to work independently and problem solve as well as effectively collaborate with various teams\\nHighly proficient in Microsoft Excel, PowerPoint, and Word\\nBachelor of Arts/Sciences in Social Sciences, Communications, Mathematics or another related field\",\n",
       "   'jobApp': 'https://www.indeed.com/rc/clk?jk=dfe62bb2c9818a96&fccid=6824fc1f087bd63e&vjs=3',\n",
       "   'salary': 'N/A',\n",
       "   'skills': 'manage,team',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [3,\n",
       "  {'location': 'Chicago, IL',\n",
       "   'company': 'Techpoint LLC',\n",
       "   'datePosted': '4 days ago',\n",
       "   'postUrl': 'https://www.indeed.com/company/Techpoint-LLC/jobs/Business-Analyst-3903a3e550cf2c80?fccid=5e7a7b3eab3b3ed2&vjs=3',\n",
       "   'jobType': 'N/A',\n",
       "   'jobTitle': 'Business Analyst - Entry Level (NO C2C)',\n",
       "   'jobDes': \"Job SummaryRole: Entry-level Business AnalystLocation: Multiple locations across the USAPermanent FTE positionSalary/Compensation – 60K/annum + benefitsEducation/Certification: -Just passed out entry-level candidates only, 2018 or 2019 passed out (Master’s Degree) with GPA – 3.00 and above.Master’s Degree from an accredited college or university with a concentration in Business, Economics or Computer Science (or equivalent diploma/work experience)Great communication skills, ability to collaborate with developers and Product ManagementParticipation and/or completion in testing certification programs (Six Sigma, CSTE, ISTQB or CSQA)Please respond if you: -Have minimum 0.5-3 years working experience in Business Analysis/Design/Development of enterprise applications - we have an ongoing opening with our clientsMust be available to join the project if an offer is madeShould have a Valid US work visaAre OPEN for RelocationBenefits: -Assistance in Resume and Interview PreparationGuidance on how to attend Vendor/ Client Interview CallsPersonal Attention for Marketing, Submissions, and InterviewsOn-Job SupportHealth BenefitsWe do sponsor work visas: / L1 /OPT /STEM OPT for eligible and qualified candidates. We also sponsor /PERM Labor I Certifications for qualified candidates.**Techpoint LLC. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, colour, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. We especially invite women, minorities, veterans, and individuals with disabilities to apply.If you are interested, please share your resume at Sachin(at)techpoint.net or apply here.Job Type: Full-timeSalary: $58,000.00 to $60,000.00 /yearExperience:business analyst: 1 year (Preferred)Education:Master's (Required)Work authorization:United States (Required)\",\n",
       "   'jobApp': 'https://www.indeed.com/company/Techpoint-LLC/jobs/Business-Analyst-3903a3e550cf2c80?fccid=5e7a7b3eab3b3ed2&vjs=3',\n",
       "   'salary': '$58,000 - $60,000 a year',\n",
       "   'skills': '',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [4,\n",
       "  {'location': 'Claremont, CA',\n",
       "   'company': 'Harvey Mudd College',\n",
       "   'datePosted': '25 days ago',\n",
       "   'postUrl': 'https://jobs.github.com/positions/03e10635-68a6-42b9-b639-922ca69bfec5',\n",
       "   'jobType': 'Full Time',\n",
       "   'jobTitle': 'Business Intelligence and Reporting Analyst',\n",
       "   'jobDes': '\\nBUSINESS INTELLIGENCE AND REPORTING ANALYST\\nPOSITION SUMMARY\\nThe Business Intelligence and Reporting Analyst (Analyst) is responsible for managing the Office of College Advancement’s (OCA) databases, including data warehousing, integration, in-depth data analysis reporting, and dashboard development. Reporting directly to the Director of Advancement Services, the Analyst is responsible for the overall lifecycle management of the Advancement Data Warehouse and reporting infrastructures. The Analyst is responsible for building, implementing, and maintaining data integrations between various databases within Advancement and throughout Harvey Mudd College. Under direction of the Director, the Analyst aids in the effort to create, implement, integrate, assess, and improve—on an ongoing basis—the College’s infrastructure and strategies required to conduct successful overall advancement efforts.\\nIn the Summer of 2019, OCA completed a database conversion to Blackbaud Raiser’s Edge NXT. The Analyst will be instrumental in the next phase of the project by creating and implementing a data warehouse and associated reports/dashboards.\\nThe Analyst must be a highly collaborative, customer centric individual who has a proven track record of effective communication skills, both verbal and written, that will thrive in a fast-paced team environment. By defining realistic timelines and goals, the Analyst must be able to advance multiple projects with competing priorities and deadlines with minimal supervision.\\nAbout Harvey Mudd College:\\nLocated in the heart of Claremont, California, 35 miles east of Los Angeles, Harvey Mudd College is a highly selective undergraduate liberal arts college offering degrees in science, technology, engineering and mathematics.  HMC enrolls about 800 students and is a member of The Claremont Colleges, which comprises five undergraduate colleges and two graduate institutions.  According to students, professors, and alumni, what makes Harvey Mudd distinctive is its collaborative, cross-disciplinary nature.  The working environment is built on collaborative relationships between and among all members of the campus community and a deep commitment to the College’s mission to educate students “so that they may assume leadership in their fields with a clear understanding of the impact of their work on society.”\\nSUMMARY OF ESSENTIAL DUTIES AND RESPONSIBILITIES\\nData Warehouse\\n\\nLead the design and implementation of a a data warehouse, ensuring departmental data is easily accessible for reporting and analysis, while safeguarding the data’s security. Maintain the data warehouse after implementation.\\nGain expert level knowledge of source system tables, application business rules, and data challenges facing OCA.\\nSupport members of the Advancement Services Team and other subject-matter experts to clean, transform, aggregate, and summarize data as needed to populate the data warehouse.\\nDevelop and maintain clear documentation on OCA’s data warehouse, ensuring staff members can effectively support the data warehouse in Analyst’s absence.\\nMonitor the OCA data warehouse to ensure nightly population processes complete successfully and identify errors.\\nThrough coordination with HMC’s IT Department (Computing and Information Services or CIS), lead the effort to develop and deploy optimal solutions that support the OCA data warehouse. Perform routine administration of system maintenance activities.\\n\\nReporting & Analysis\\n\\nCollaborate with fellow OCA team members and interpret their requests to design, program, and deliver customized reports and dashboards tailored to fit their needs, ensuring data accuracy and consistency.\\nIn collaboration with the Director, design solutions to improve workflows and streamline processes.\\nDevelop and maintain clear and complete documentation on all reports and dashboards.\\nEngage with the Advancement Services team and key stakeholders to ensure regular data validation scripts and queries are executed.\\nTrain power-users to be able to pull ad-hoc queries and/or reports.\\n\\nData Integrations\\n\\nDevelop integrations in Dell Boomi, or when necessary other techniques, to allow for fast and consistent data flow between various OCA databases (Blackbaud Raiser’s Edge NXT, iModules, Salesforce Marketing Cloud, etc.) and, through partnership with CIS resources, other HMC databases (Workday, Identity Access Management, etc.)\\nDevelop and maintain clear and complete documentation on integrations to be shared throughout the campus, ensuring clarity between departments around data flows and system of record details.\\nIn coordination with CIS, pass data from Advancement to other College databases.\\n\\nDatabase Administration\\n\\nManage security and access for all users within Blackbaud Raiser’s Edge NXT, Power BI, and other OCA databases/reporting tools.\\nAssist end-users with issues utilizing Blackbaud Raiser’s Edge NXT, coordinating with Blackbaud Support or HMC CIS when necessary.\\nIn collaboration with the Director, aid in the creation and implementation of departmental policies and procedures to ensure compliance with the College’s policies regarding data security and privacy, document retention, and other relevant policies.\\nMaintain strong working relationships with OCA’s various vendors, ensuring awareness of upcoming enhancements, maintenance windows, etc.\\nGeneral\\nMaintain a close working relationship with both HMC’s CIS and the IT departments throughout The Claremont Colleges and The Claremont Colleges Services (TCCS) through effective communication and collaboration on common data projects.\\nThrough in-person or virtual training, classes, conferences, or similar, keep current with the latest trends in data management and analysis technology. Partner with the Director to roll out new features/enhancements to the department.\\nAs required, participate in the assessment, evaluation, and selection of vendor products related to OCA and HMC data to support the department’s and College’s mission.\\nRepresent OCA on various data-related committees throughout HMC, including the HMC Data Governance and Standards Team (DGST).\\nPerform other responsibilities and tasks as assigned.\\n\\nREQUIRED QUALIFICATIONS AND EXPERIENCE\\nEducation & Experience:\\n\\nBachelor’s degree in Computer Science, Information Systems, Business System Administration or related field. Or any combination of relevant education, training, and experience that provides the required knowledge, skills, and abilities of the position.\\nMinimum five years’ experience with data analysis and reporting.\\nMinimum three years’ experience designing, implementing, and maintaining data warehouses.\\nMinimum three years’ experience building and maintaining data integrations and APIs.\\nMinimum two years’ experience database administration.\\n\\nPREFERRED QUALIFICATIONS\\n\\nAdvanced degree in Computer Science, Information Systems, Business System Administration or related field.\\nDell BOOMI Developer Certification or equivalent experience with other integration tools such as Snaplogic, Informatica, or Workato; familiarity with RESTful Web Services and APIs.\\nExperience in higher education and/or fundraising/advancement, including an understanding of the advancement processes and terminology.\\nExperience supporting and/or administering Blackbaud Raiser’s Edge (v.7 or NXT, NXT preferred).\\nFamiliarity with Workday, Salesforce Marketing Cloud, Import-O-Matic, and/or iModules.\\nExperience with maintaining Windows Server 2012/2016 systems.\\nKnowledge of Microsoft Flow and Power Apps.\\n\\nRequired Knowledge, Skills and Abilities:\\n\\nProven experience with data warehouse design and implementation, data warehousing life cycle and dimensional modeling.\\nAdvanced SQL programming experience.\\nExtensive experience with Microsoft Power BI, Query Editor, M, Report Builder (paginated reports), etc.\\nAdvanced experience writing and troubleshooting issues with SQL queries, scripts, or stored procedures to perform ETL (Extract, Transform, and Load) processes.\\nExcellent information technology skills with aptitude to learn and effectively utilize a variety of software tools at a “power user” level.\\nDemonstrated experience building and maintaining APIs. Experience in data systems integrations involving multiple data sources of varying complexities.\\nProject management experience with demonstrated ability to estimate, plan, prioritize, and deliver projects on time.\\nExtremely high level of attention to detail and proven ability to problem solve.\\nAbility to communicate in a clear and concise manner whether verbally, in writing, or in person.\\nExperience communicating with a wide variety of audiences, tailoring the level of technical detail in explaining complex ideas accordingly.\\n\\nPHYSICAL REQUIREMENTS\\nFrequent sitting for extended periods of time. Constant use of keyboard. Specific vision requirements include close vision, distance vision, and the ability to adjust focus. Occasional moderate lifting of 10-20 lbs.\\nPOSITION CHARACTERISTICS\\nHours: The regular office hours of this position are 8:00 a.m. to 5:00 p.m. including a one-hour meal period, Monday-Friday. Hours may vary due to the needs of the College or department. Occasional evening and weekend hours may be required.\\nClassification & Status: This is a full-time, regular, 12-months per year, benefits-eligible, exempt position.\\nReports to: Director of Advancement Services.\\nApplication Procedures:\\nPlease visit www.hmc.edu/employment to view a complete job description for this position and obtain information about how to submit an application.   Information about HMC’s competitive benefits package is available at www.hmc.edu/hrbenefits.\\nDeadline to apply:\\nPosition will remain open until filled.\\nThis job description defines the essential job duties of the position. Harvey Mudd College expects that employees hired for this position can perform the essential functions of the job without imposing risk of substantial harm to the health or safety of themselves or others.  It may also include marginal functions, generally defined within Title I of the Americans with Disabilities Act.\\nRegular employment at the College is for no specified period of time; conditions and status of employment (hours, pay, title, duties, etc.) are subject to change at any time. Employment is at-will and employees, and likewise the College, are free to end the employment relationship at any time, for any reason, with or without notice or cause, unless otherwise prohibited by law.\\n',\n",
       "   'jobApp': 'http://www.hmc.edu/employment',\n",
       "   'salary': 'N/A',\n",
       "   'skills': 'sql,manage,team',\n",
       "   'category': 'Deep Learning',\n",
       "   'education': 'graduate,undergraduate'}],\n",
       " [5,\n",
       "  {'location': 'Palatine, IL 60067',\n",
       "   'company': 'Township High School District 211',\n",
       "   'datePosted': '2 days ago',\n",
       "   'postUrl': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BvRTtPYviBXXga901bZda-x9dVbr3mkLrPNoe7KgsTz5g1hPoH2EoBlgnt380iiJ9SP3gpwfqzpDUYeIhFusRhMaF0LfqUmhMpdA6eGJEVVOz-ei1NwABX4G7TYmkLhaJ2xiSlVTTwGcGw_-ZwT-1m2bfD1GI8QiGPsyTym2rCR2Q3_HOPxCclLGy8CoYUvTmu4PAcZ1SYiM2Rhoqx7rGqueWSCeT7zNDxdjREhwSMLTZliAIr-4433ATcZEslP3rv5bc5mPs7N4tgSEP0p2qJhaLi28p_swtwGdAuAvirs0cNUZ6-f7Raju_IP4vwwi0XRXLUcyn5y632oopK0bKsTWb8qjRgAnzJq82f5h_fO7hVk9jLb5H-ofcdrEMIleBroON6RFuyzTLTh-0FVq8uYQsv-2pGXCrWDUwEIUqth6LrVJ_DCOOv&p=5&fvj=1&vjs=3',\n",
       "   'jobType': 'N/A',\n",
       "   'jobTitle': 'Data Analyst',\n",
       "   'jobDes': 'POSITION:  Data Analyst at Township High School District 211POSITION SUMMARY: Township High School District 211 is looking for an experienced Data Analyst who is able to turn business requirements into custom-formatted data reports. The ideal Data Analyst must be highly analytical and detail-oriented to ensure reports are accurate, to complete all required steps of operational processes, and to document work steps.The primary responsibilities include but are not limited to the following:1. Create, maintain, and test SQL Server queries for reports2. Create, maintain, and test SSRS reports3. Run weekly process to upload student and teacher data to the state4. Create, maintain, and test Tableau visualizations5. Create ad-hoc queries and send messages via Infinite Campus6. Use SQL stored procedures to update dataEXPERIENCE: * Minimum two-year Microsoft SQL Server querying experience* Previous experience using Microsoft SSRS in prior roles* Solid experience creating and modifying stored procedures in SQL* Experience testing reports for accuracy and comprehensiveness* Any experience with Infinite Campus, Tableau, ISBE, or data warehouse would be a plusSKILLS: * Strong analytical skills* Candidate must have very strong computer skills including knowledge of Microsoft Excel* Strong communication skills, both written and verbal* Detail-oriented team player with ability to handle multiple projects in fast-paced environment* Candidate must be able to work independently and provide reliable and timely work* Strong documentation and organization skills* Able to learn efficiently* Positive attitude* Ability to collaborate effectively and work as part of a teamREQUIREMENTS AND MINIMUM EDUCATION LEVEL: * Bachelor’s degree required.* Degree in computer science, data, or programming preferred.Candidate must pass a drug screening and criminal background check.Job Type: Full-timeSalary: $60,000.00 to $70,000.00 /yearExperience:Microsoft SQL Server querying: 2 years (Preferred)Work Location:One locationBenefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time offParental leaveTuition reimbursementSchedule:Monday to Friday',\n",
       "   'jobApp': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BvRTtPYviBXXga901bZda-x9dVbr3mkLrPNoe7KgsTz5g1hPoH2EoBlgnt380iiJ9SP3gpwfqzpDUYeIhFusRhMaF0LfqUmhMpdA6eGJEVVOz-ei1NwABX4G7TYmkLhaJ2xiSlVTTwGcGw_-ZwT-1m2bfD1GI8QiGPsyTym2rCR2Q3_HOPxCclLGy8CoYUvTmu4PAcZ1SYiM2Rhoqx7rGqueWSCeT7zNDxdjREhwSMLTZliAIr-4433ATcZEslP3rv5bc5mPs7N4tgSEP0p2qJhaLi28p_swtwGdAuAvirs0cNUZ6-f7Raju_IP4vwwi0XRXLUcyn5y632oopK0bKsTWb8qjRgAnzJq82f5h_fO7hVk9jLb5H-ofcdrEMIleBroON6RFuyzTLTh-0FVq8uYQsv-2pGXCrWDUwEIUqth6LrVJ_DCOOv&p=5&fvj=1&vjs=3',\n",
       "   'salary': '$60,000 - $70,000 a year',\n",
       "   'skills': 'sql,team',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [6,\n",
       "  {'location': 'Newmarket, ontario',\n",
       "   'company': 'York Region',\n",
       "   'datePosted': '11 days ago',\n",
       "   'postUrl': 'https://jobs.github.com/positions/ab809c58-73a7-4b8b-ba2f-4a59fcd7c6ac',\n",
       "   'jobType': 'Contract',\n",
       "   'jobTitle': 'Environmental Business Intelligence and Data Warehouse Analyst #25099',\n",
       "   'jobDes': '\\nDEPARTMENT: Environmental Services Department\\nBRANCH: Business Planning and Operations Support\\nSalary: $44.63 to $ 48.51 per hour\\nLOCATION: 145 Harry Walker Parkway, Newmarket\\nSTATUS: Temporary Full-Time, Approx. 12 months\\nSCHEDULED WEEKLY HOURS: 35\\nSCHEDULED SHIFTS: 0830 – 1630\\nThis is a Replacement\\nUnion position - CUPE Local 905 (York Region Unit)\\nPOSITION PURPOSE\\nReporting to the Program Manager, Data Management & Business Intelligence is responsible for extracting, mining, evaluating, analyzing and researching data generated from Data Warehouse and Business Intelligence (DWBI) system and preparing and delivering statistical and narrative reports; enable users access to quality data for the Department; collecting, analyzing, interpreting, summarizing, creating, and maintaining data files to support Department and Corporate systems software configurations; supporting the installations of hardware and software upgrades and new equipment configurations as related to DWBI; providing system support for the development, implementation, operation and maintenance of specialized automated systems and related applications, as required; and providing DWBI solutions and support to enable individuals to access quality data.\\nMAJOR RESPONSIBILITIES\\n\\nCoordinates and provides support for the implementation of DWBI projects in the Department.\\nExtracts, mines, evaluates, analyzes, and researches data from the Data Warehouse which contains data from the various systems.\\nAssesses impact of DWBI system on existing business processes and procedures and makes recommendations to management staff for revisions and develops transition plans.\\nResearches, analyzes, organizes, implements and documents data acquisition, transformation, creation and maintenance processes, and ensures that data meets Department’s quality requirements.\\nMaintains data approval workflow.\\nDesigns and maintains Extract Transfer Loads process and validates results with business users.\\nAssists data owners and end users to perform data validation quality checks; reviews and analyzes the results of program and systems testing with end users.\\nAssists with the development and analysis of data standards; identifies issues and assists with/implements resolutions.\\nLiaises with internal staff, providing systems expertise and support; shares information regarding initiatives and other best practices with Branch and Department staff.\\nLiaises with vendors/business owners of source systems and with external vendors on software and hardware updates, new product initiatives, and other systems related information, in conjunction with ITS Branch.\\nMaintains expertise by reviewing technical literature, attending seminars, conferences and training as directed and shares information regarding initiatives and other best practices with Branch and Department staff.\\nPerforms backup duties of other Business Data and Technology Management staff, as assigned.\\n\\nQUALIFICATIONS\\n\\nSuccessful completion of a Community College Diploma in Information Technology, Computer Sciences or approved equivalent combination of education and experience.\\nMinimum three (3) years of demonstrated hands-on experience extracting, mining, analyzing, and reporting technical data generated from data management systems, data integrity and security; creating and maintaining data files to support software configurations; and experience using Windows Servers and workstations.\\nDemonstrated experience using Crystal Reports.\\nKnowledge of data, internet, and networking technologies, Data Warehouse and Business Intelligence.\\nKnowledge of database and programming languages (e.g.  PL/SQL, Visual Basic, SQL, Oracle, JavaScript, HTML,  XML, SharePoint, SCADA, Maximo, MCADI, GIS, RIVA, MS Project Server, PeopleSoft).\\n\\n',\n",
       "   'jobApp': 'http://Client.njoyn.com/CL2/ex/JobDetails4.ASP?CLID=60295&BDID=1&JID=J0220-0392&LANG=1',\n",
       "   'salary': 'N/A',\n",
       "   'skills': '',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [7,\n",
       "  {'location': 'Boston, MA',\n",
       "   'company': 'Acadian Asset Management',\n",
       "   'datePosted': 'over 1 year ago',\n",
       "   'postUrl': 'https://jobs.github.com/positions/47328346-e90c-11e8-9429-c09930ae6ec9',\n",
       "   'jobType': 'Full Time',\n",
       "   'jobTitle': 'Full Stack Developer & Senior Analyst (Investment Analytics)',\n",
       "   'jobDes': '\\nPosition Overview:\\nWe are seeking an experienced Software Engineer to help us design and build Acadian’s advanced browser-based, interactive, analytical platform that helps us better understand, explain, and improve our quantitative investment process. This is a hands-on, full-stack development role that provides growth and learning opportunities. The Software Engineer will utilize and hone a variety of technical skills while gaining and applying quantitative investment knowledge. Our small team is embedded within the investment group, providing the opportunity to see your work in action. Join us to leverage your software development skills and work with world class technology and investment experts.\\nResponsibilities:\\n\\nDesign, build, test, and support multi-tiered distributed, clustered, web-based applications and platforms\\nEngineer, design, and build scalable, interactive, responsive, informative, and beautiful data visualization and exploration tools\\nTeam up with quantitative portfolio managers and researchers to develop and execute process improvement initiatives through software development\\n\\nQualifications:\\n\\nExperience building browser-based applications using JavaScript, CSS, and HTML\\nExperience programming using a server-side scripting language such as Python (Node, Ruby, Julia, etc.)\\nDegree in Computer Science or equivalent knowledge and technical work experience\\nHands on experience running http server such as Apache / NGINX\\nPrior investment/financial industry knowledge is not required\\n\\nOther technologies we use:\\n\\nSQL, NoSQL, MongoDB, Redis\\nNumpy, Scipy, Pandas\\nD3, AngularJS, Node\\nDocker, Slurm, ZeroMQ, AWS\\n\\nIt is the policy of Acadian Asset Management LLC to provide equal employment opportunity to all qualified persons without regard to race, creed, color, sex, age, national origin, marital status, veteran status, citizenship status, disability, or sexual orientation.\\n',\n",
       "   'jobApp': 'https://www.acadian-asset.com/careers',\n",
       "   'salary': 'N/A',\n",
       "   'skills': 'python,team,html,aws',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [8,\n",
       "  {'location': 'Chicago, IL',\n",
       "   'company': 'IntelliSweep, Inc.',\n",
       "   'datePosted': '4 days ago',\n",
       "   'postUrl': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BkVWyDDj4meUiEl9hSv_oC9r_LkYu15p-4cT0cTcoHTqhtFAAdZE3qG_xU9iwDKdAfWRQx2I15hxA-0nUjEsGwmRjotj4XLJXbUM0DyUY9G_HiZVu-uw9zp1ax08e0861d7bIzd4na8NKjjdLuksOUPG52vdc3yFsXIP8Ldx5hsev_Yop-aODgVFS9q2q3unkTe8TwGg2Gw2_UsFZUndKDmhmJhrxi7IGIlZuThI4bD8spE5l1xvEksyn2iFBW7dJ7vR8FbxvqVWZZc7G5i9MaEtaiAcnJZUplrBdkWcns44fKjKmNRIh_j7n4Z-0UWj10-AXIMi3fBkTpIlP8GyHPDohyxI3YXgQRD9ogfJ1xh8Kgc3Cp4milRj79oLWEnuegkok6VQHrvuaTmGmfO2L5Os59pF-DaoeV0MR1tZBeqqnVI9gTDJ0C4Rl-Ho-BdeY=&p=3&fvj=1&vjs=3',\n",
       "   'jobType': 'N/A',\n",
       "   'jobTitle': 'Investigative Analyst',\n",
       "   'jobDes': \"DigiStream Investigations, a fast-growing national private investigations firm, seeks a talented addition to our investigative team in the Chicago, IL region. We are looking for an independent, motivated individual who wants to get started in the world of Private Investigations!Job Title: IntelliSweep Investigative AnalystOffice Location: Lombard, ILSchedule: Full-Time, 7:30AM - 4:30PMBenefits: :  Health, Dental, Vision, and Life insurance offered, and 401(k) retirement plan with 4% Company Match offered**This is an exciting entry-level position with a lot of opportunity for growth! Job Summary: The Investigative Analyst will conduct telephonic-based assignments for the affiliate which include Medical Sweeps and Specialty Sweeps. This requires a strong ability to analyze a subject’s background information and determine proper facilities for our clients from a vast geographical area in addition to summarizing and cataloging these efforts into a report.Responsibilities: - Review information on a subject and determine the best course for the investigation- Locate logical facilities from a variety of sources for inclusion into the investigation- Telephone-based communication conducted on dozens of these facilities in order to determine a subject’s treatment history- Compose informative and organized reports that summarize these phone calls- Satisfy ancillary assignments on as-needed basis- Trusted with confidential information- Perform any assignments thoroughly and efficiently using investigative acumen- Keep track of all ongoing assignments- Brief affiliate team with your results during ops meetings- Review the assignment and discuss the clients’ goals- Determine whether there is any actionable information- Determine whether other services may assist the client- Other duties may be added from time to time- Ensure quantity and quality of reports each month meet the standard of the affiliateRequirements: - Bachelor’s Degree preferred (Criminal Justice, Psychology, History, Political Science or other writing intensive major), but NOT required. Experience as an Administrative Assistant or other office setting involving interpersonal and telephone communication also valued- Comfort with communicating with numerous facility types (usually in the medical field) on a daily basis and keeping track of the results of these calls- Familiarity and comfort with navigating ambiguity as well as a basic understanding of the workers' compensation system or desire to learn the system- Ability to read, analyze, and distill large amounts of information from social networking profiles and online forms and articles, and apply it to an investigation- Ability to interpret a variety of instructions furnished in written, oral, diagram, or schedule form.- Ability to maintain confidentiality of information- Ability to juggle multiple investigative reports at once while maintaining work quality and turnaround time while communicating effectively with supervisorNO PHONE CALLS, PLEASEAgency License# 117001839Job Type: Full-timeSalary: $15.00 /hourEducation:Bachelor's (Required)Work Location:One locationBenefits:Health insuranceDental insuranceVision insuranceRetirement plan\",\n",
       "   'jobApp': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BkVWyDDj4meUiEl9hSv_oC9r_LkYu15p-4cT0cTcoHTqhtFAAdZE3qG_xU9iwDKdAfWRQx2I15hxA-0nUjEsGwmRjotj4XLJXbUM0DyUY9G_HiZVu-uw9zp1ax08e0861d7bIzd4na8NKjjdLuksOUPG52vdc3yFsXIP8Ldx5hsev_Yop-aODgVFS9q2q3unkTe8TwGg2Gw2_UsFZUndKDmhmJhrxi7IGIlZuThI4bD8spE5l1xvEksyn2iFBW7dJ7vR8FbxvqVWZZc7G5i9MaEtaiAcnJZUplrBdkWcns44fKjKmNRIh_j7n4Z-0UWj10-AXIMi3fBkTpIlP8GyHPDohyxI3YXgQRD9ogfJ1xh8Kgc3Cp4milRj79oLWEnuegkok6VQHrvuaTmGmfO2L5Os59pF-DaoeV0MR1tZBeqqnVI9gTDJ0C4Rl-Ho-BdeY=&p=3&fvj=1&vjs=3',\n",
       "   'salary': '$15 an hour',\n",
       "   'skills': 'team',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}],\n",
       " [9,\n",
       "  {'location': 'Sparta, WI',\n",
       "   'company': 'IEH Laboratories',\n",
       "   'datePosted': '2 days ago',\n",
       "   'postUrl': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BGhNnK4Bc6AtnLXIcLIeETSGEDmqVfV8qnsITF0XvznL_MvFIHOqceCzfwPKshlif_NnXz58t_RWC5HOTsf772zNlOew2YVBtNa7xzizY0WstGvinTeRGfCR0F42Vof69utlXv5trcMGhVNBln7-nrEHFx1M7ueYjK40NBRiz2ythJjG8GqlCq0gL8nIISLoLjMZ_fC3H4m9G0vc9sqp9B2nzakyvBn0k8PzZlWLx-BiwlFpu8A5UObCKPGonFiHO2Z4HCH_n0mVqzhFR8pDvnbF1VRMFPyIm_h7wvLcOoXWwuY3A-OHrpgTJN79iahlRuNh5IOsD3VxQDakibAMCKgm6H0hWfPBwibvWh1Zx-wWKf86netXIKMJ7a18FN1E0P_E9iQ8oz6dgn7MQiFz7zOw3-ScrD0qc0eg34aA2KyYvxO1iyxgqJPqpCldKPQ4Q=&p=4&fvj=1&vjs=3',\n",
       "   'jobType': 'N/A',\n",
       "   'jobTitle': 'Laboratory Analyst (Sparta, WI)',\n",
       "   'jobDes': 'IEH Laboratories, a Leader in Food Safety, is now accepting applications for the Laboratory Analyst position at its facility in Sparta, WI.Applicants must possess a BS or BA in the biological sciences or a related field.Ideal candidates should possess the following skills:- Strong attention to detail- Proficiency with data entry and computer applications- Multitasking capability- Ability to work in a fast-paced environment- Strong written and verbal communication skills- Self-motivated- Strong understanding of aseptic technique in the laboratoryThe Laboratory Analyst duties include: analysis of food samples for pathogens via PCR and immunoassay, various microbe enumerations, data entry, laboratory reporting, quality control, and media preparation. This is a full-time position in which the employee will be eligible for standard benefits after a brief waiting period.The laboratory operates weekends, so candidates must be willing to work nights and weekends.The schedule for this position is 6:00AM to 4:00PM.Due to exposure to various food allergens in the laboratory environment, applicants with moderate to severe food allergies are discouraged from applying.Click the \"View or apply to job\" link below to apply.You will be asked to complete optional self identification surveys and submit your cover letter, resume and references in a combined, single PDF.Equal Opportunity Employer M/F/V/D\"EEO is the Law\" Poster: http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdfJob Type: Full-timeEducation:Bachelor\\'s (Required)Work Location:One locationBenefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time off',\n",
       "   'jobApp': 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BGhNnK4Bc6AtnLXIcLIeETSGEDmqVfV8qnsITF0XvznL_MvFIHOqceCzfwPKshlif_NnXz58t_RWC5HOTsf772zNlOew2YVBtNa7xzizY0WstGvinTeRGfCR0F42Vof69utlXv5trcMGhVNBln7-nrEHFx1M7ueYjK40NBRiz2ythJjG8GqlCq0gL8nIISLoLjMZ_fC3H4m9G0vc9sqp9B2nzakyvBn0k8PzZlWLx-BiwlFpu8A5UObCKPGonFiHO2Z4HCH_n0mVqzhFR8pDvnbF1VRMFPyIm_h7wvLcOoXWwuY3A-OHrpgTJN79iahlRuNh5IOsD3VxQDakibAMCKgm6H0hWfPBwibvWh1Zx-wWKf86netXIKMJ7a18FN1E0P_E9iQ8oz6dgn7MQiFz7zOw3-ScrD0qc0eg34aA2KyYvxO1iyxgqJPqpCldKPQ4Q=&p=4&fvj=1&vjs=3',\n",
       "   'salary': 'N/A',\n",
       "   'skills': '',\n",
       "   'category': 'Artificial Intelligence',\n",
       "   'education': ''}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.getNJobsByQuery('analyst', 'jobTitle', 0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the given list to a string\n",
    "def lst_to_str(lst):\n",
    "    return ','.join(lst)\n",
    "\n",
    "# converts the given string to a list\n",
    "def str_to_lst(stri):\n",
    "    return stri.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGES\n",
    "# + updated to match commit 701d273a962d13486985e1c8852af6733eab4f77\n",
    "# + updated to match commit fa30ef6af9ef9659831d2fbc5e526715340fc29e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('USERS',), ('JOBS',)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"Flask_Jade_Sample/TestFlaskJadeWeb/Users.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.destroyJobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.getAllJobs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
